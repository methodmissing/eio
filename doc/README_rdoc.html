<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type" />

  <title>File: README.rdoc [eio - a libeio wrapper for Ruby]</title>

  <link type="text/css" media="screen" href="./rdoc.css" rel="stylesheet" />

  <script src="./js/jquery.js" type="text/javascript"
    charset="utf-8"></script>
  <script src="./js/thickbox-compressed.js" type="text/javascript"
    charset="utf-8"></script>
  <script src="./js/quicksearch.js" type="text/javascript"
    charset="utf-8"></script>
  <script src="./js/darkfish.js" type="text/javascript"
    charset="utf-8"></script>
</head>

<body class="file">
  <div id="metadata">
    <div id="home-metadata">
      <div id="home-section" class="section">
        <h3 class="section-header">
          <a href="./index.html">Home</a>
          <a href="./index.html#classes">Classes</a>
          <a href="./index.html#methods">Methods</a>
        </h3>
      </div>
    </div>

    <div id="project-metadata">
      
      
      <div id="fileindex-section" class="section project-section">
        <h3 class="section-header">Files</h3>
        <ul>
        
          <li class="file"><a href="./README_rdoc.html">README.rdoc</a></li>
        
        </ul>
      </div>
      

      <div id="classindex-section" class="section project-section">
        <h3 class="section-header">Class Index
          <span class="search-toggle"><img src="./images/find.png"
            height="16" width="16" alt="[+]"
            title="show/hide quicksearch" /></span></h3>
        <form action="#" method="get" accept-charset="utf-8" class="initially-hidden">
        <fieldset>
          <legend>Quicksearch</legend>
          <input type="text" name="quicksearch" value=""
            class="quicksearch-field" />
        </fieldset>
        </form>

        <ul class="link-list">
        
          <li><a href="./EIO.html">EIO</a></li>
        
          <li><a href="./EIO/Middleware.html">EIO::Middleware</a></li>
        
          <li><a href="./EIO/Request.html">EIO::Request</a></li>
        
          <li><a href="./EM.html">EM</a></li>
        
          <li><a href="./EM/EioHandler.html">EM::EioHandler</a></li>
        
        </ul>
        <div id="no-class-search-results" style="display: none;">No matching classes.</div>
      </div>

      
    </div>
  </div>

  <div id="documentation">
    
<h1>eio - a libeio wrapper for Ruby</h1>

<p>© 2011 Lourens Naudé (methodmissing)</p>

<pre>http://github.com/methodmissing/eio</pre>

<h2>Why you may need this</h2>

<p>Changing a file descriptor that references a normal file to non-blocking
mode (O_NONBLOCK flag) have absolutely no effect. Regular files are always
readable and always writable. Readability and writability checks will also
succeed immediately. Such operations can however still block for a
undefined amount of time - busy disks, slow disks (EBS) etc. and usually
also include a chunk of disk seek time as well Manipulating directories,
stat’ing files, changing permissions, ownership etc. is only defined
through synchronous APIs. This is a major drawback for environments where
throughput is critical and a high degree of interactivity is demanded at
all times.</p>

<h2>How it works</h2>

<p>A number of OS (pthread) threads is started to execute blocking I/O
requests and signal their completion. The I/O operations will still block,
but you’re application’s able to do something else and will be notified
of completion status sometime in the future. This library wraps libeio (<a
href="http://software.schmorp.de/pkg/libeio.html">software.schmorp.de/pkg/libeio.html</a>),
which also powers node.js’s FS module and supports both Ruby MRI 1.8 and
1.9.</p>

<p>It’s designed to run in a single threaded environment and libeio will
manage a pool of OS threads, effectively scheduling out I/O ops across
multiple cores. This is the same pattern very common in implementations of
the Reactor Pattern (<a
href="http://en.wikipedia.org/wiki/Reactor_pattern">en.wikipedia.org/wiki/Reactor_pattern</a>,
Eventmachine) where I/O requests and callbacks are always submitted and
handled on the reactor thread. This library thus naturally fits into event
driven applications and exposes a file descriptor that can wake up an event
loop when readable and execute callbacks for completed requests on the
reactor thread as well.</p>

<p>Event loop integration is however much closer to the Proactor Pattern (<a
href="http://en.wikipedia.org/wiki/Proactor_pattern">en.wikipedia.org/wiki/Proactor_pattern</a>).
The I/O multiplexer in a Reactor implementation merely notifies of file
descriptor state changes - a handler is still responsible for reading or
writing data on the reactor thread. Callbacks for file system and other
blocking system calls wrapped by this library receive results as arguments
- there’s nothing else to do. Nothing to read, nothing to write, no
system calls or other context switches. In other words, the Reactor pattern
asynchronously notify of state changes, but act on those synchronously, on
the Reactor thread, which incurs some processing overhead.</p>

<p>In addition to wrapping known blocking system calls, libeio also expose
several fallback implementations such as readahead, sendfile etc. and is
also very effective with system calls that incur a lot of CPU overhead
managing user space buffers, memcpy etc.</p>

<h2>Sweet Spot</h2>

<p>This library solves a specific problem of avoiding blocking I/O work on
POSIX APIs that traditionally don’t support the O_NONBLOCK flag or only
have a synchronous interface defined. As with most event driven I/O, the
goal is increased throughput and not necessarily a faster per request
guarantee. To serve more clients with the same or less infrastructure
without degrading quality of service.</p>

<h2>Requirements</h2>
<ul><li>
<p>A POSIX compliant OS, known to work well on Linux, BSD variants and Mac OS
X</p>
</li><li>
<p>Ruby MRI 1.8 or 1.9</p>
</li><li>
<p>Platform that supports the <em>VA_ARGS</em> macro.</p>
</li><li>
<p>It’s recommended to use this library in conjunction with an event loop</p>
</li><li>
<p>Best results with I/O bound work on disks / volumes with variable
performance characteristics, such as Amazon EBS.</p>
</li></ul>

<h2>Installation</h2>

<p>Rubygems installation</p>

<pre>gem install eio</pre>

<p>Building from source</p>

<pre>git clone git@github.com:methodmissing/eio.git
rake compile:eio_ext</pre>

<p>Running tests</p>

<pre>rake test</pre>

<h2>Documentation</h2>

<p>See <a
href="http://methodmissing.github.com/eio">methodmissing.github.com/eio</a>
for RDOC documentation.</p>

<h2>How to - with an event loop</h2>

<p>The Eventmachine handler watches the read end of a pipe which wakes up the
event loop whenever there’s results to process. This is entirely driven
from libeio which writes a char to the write end of the pipe to wake up the
loop. The <a href="EIO.html#method-c-poll">EIO.poll</a> callback will fire
as many times as it needs to as we don’t read data from the pipe through
the reactor. A separate callback invoked by libeio will read the char and
clear it’s readable state.</p>

<pre>require 'eio/eventmachine'

EM.run do
  EIO.eventmachine_handler # let libeio notify when there's result callbacks to invoke

  EIO.open(__FILE__) do |fd|
    EIO.read(fd) do |data|
      p data
      EIO.close{ EM.stop }
    end
  end
end</pre>

<h2>How to - manually drain the result queue</h2>

<p>This library ships with trivial Rack middleware that acts like a barrier at
the end of each request. This pattern can be applied to any other context
as well.</p>

<pre>module EIO
  class Middleware
    def initialize(app, opts = {})
       @app = app
       @options = opts
    end

    def call(env)
      ret = @app.call(env)
      EIO.wait # flush the libeio request queue
      ret
    end
  end
end

use EIO::Middleware</pre>

<p>The call to <a href="EIO.html#method-c-wait">EIO.wait</a> blocks until
callbacks for all completed requests have been invoked. This workflow is
comparable to a 100m race with each line representing a libeio request and
<a href="EIO.html#method-c-wait">EIO.wait</a> being the finishing line /
completion barrier. Each I/O operation may be scheduled on a different CPU
core and will complete in parallel, proportional to the slowest request,
with some minor overhead to boot.</p>

<p>See the unit tests for further examples.</p>

<h2>Configuration</h2>

<p>The thread pool can be configured for specific workloads. It’s very
important to schedule callback processing in small batches when integrating
with an event loop to not block other work. Use EIO.max_poll_time and
EIO.max_poll_request to restrict time spent or callbacks invoked per libeio
notification.</p>

<pre># Set the maximum amount of time spent in each eio_poll() invocation
EIO.max_poll_time = 0.1

# Set the maximum number of requests by each eio_poll() invocation
EIO.max_poll_reqs = x</pre>

<p>Hundreds of threads can be spawned, however do note that stack sizes vary
significantly between platforms and this will most definitely affect your
memory footprint. The default pool size is 8 threads.</p>

<pre># Set the minimum number of libeio threads to run in parallel. default: 8
EIO.min_parallel = x

# Set the maximum number of AIO threads to run in parallel. default: 8
EIO.max_parallel = x

# Limit the number of threads allowed to be idle
EIO.max_idle = x

# Set the minimum idle timeout before a thread is allowed to exit
EIO.idle_timeout = x</pre>

<h2>Visibility</h2>

<p>A simple API for integration with monitoring infrastructure’s exposed as
well. These stats may not be very insightful or even accurate for a small
number of in flight requests.</p>

<pre># Number of requests currently in the ready, execute or pending states
EIO.requests

# Number of requests currently in the ready state (not yet executed)
EIO.ready

# Number of requests currently in the pending state
EIO.pending

# Number of worker threads spawned
EIO.threads</pre>

<h2>Managing requests</h2>

<p>Use the following methods for manually scheduling request processing.</p>

<pre># Read end of the pipe an event loop can monitor for readability
EIO.fd

# Called when pending requests need finishing. The amount of work done is controlled by
# EIO.max_poll_time and EIO.max_poll_requests
EIO.poll

# Drain / flush all pending requests. This method blocks until all requests have been processed,
# regardless of configuration constraints imposed on requests per EIO.poll invocation.
EIO.wait</pre>

<h2>Todo</h2>
<ul><li>
<p>Finer grained priority support, especially stacked open, read etc.</p>
</li><li>
<p>Grouped requests</p>
</li><li>
<p>Richer <a href="EIO/Request.html">EIO::Request</a> API</p>
</li><li>
<p>Implement and support all libeio wrapped syscalls</p>
</li><li>
<p>Better guidelines for optimal configuration and tuning</p>
</li></ul>

<h2>Contact, feedback and bugs</h2>

<p>This project is very much work in progress and I’m looking for guidance
on API design, use cases and any outlier experiences. Please log bugs and
suggestions at <a
href="https://github.com/methodmissing/eio/issues">github.com/methodmissing/eio/issues</a></p>

<p>Thanks !</p>

  </div>

  <div id="validator-badges">
    <p><small><a href="http://validator.w3.org/check/referer">[Validate]</a></small></p>
    <p><small>Generated with the <a href="http://deveiate.org/projects/Darkfish-Rdoc/">Darkfish
      Rdoc Generator</a> 2</small>.</p>
  </div>
</body>
</html>

